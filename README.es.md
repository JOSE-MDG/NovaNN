# ‚≠ê MiniNN Framework

## üåê Available languages / Idiomas disponibles

- üá¨üáß [English](README.en.md)
- üá™üá∏ [Espa√±ol](README.es.md)

Este mini framework ofrece herramientas y ejemplos para la creaci√≥n de redes neuronales
**MLP** junto con modulos que brindan soporte y mejoran el entrenamiento de la red.
Este proyecto intenta reflejar una buena compresi√≥n y dominio sobre funcionan estas redes
inspirado en como lo hacen los frameworks de deep learning m√°s populares como **Pytorch** y **Tensorflow**,
espcialmente **Pytorch** que fue la base en la que se inspiro este proyecto.

**Aclaracion**: Es este mini framework busca demostrar solidas bases y conocimientos sobre como funciona:
las redes neuronales, Deep Leaning, Machine Learning, matemat√≠cas, ingenieria de software, buenas practicas,
tests unitarios, Dise√±o de modular y preprocesamiento de datos.

## Introducci√≥n

- Este proyecto tiene una estrcutura completamente **modular**; incluye un directorio
  llamado `examples/` con ejemplos de **Clasificaci√≥n binaria**, **Clasificaci√≥n multiclase**
  y **Regresion** de como se puede utilizar las herramientas que posee este mini framework.

- El directorio `data/` posee datasets como _fashion-mnist_ y _mnist_ donde _fashion-mnist_
  fue utilizado para comparar el performance del proyecto con otro framework y _mnist_ para realizar un ejemplo de uso normal de clasificaci√≥n en el directorio `examples/`

- Se realizo una revisi√≥n, preprocesamiento y divisi√≥n previa de datos en `notebooks/exploration.ipynb`
  donde se visualizarion los datasets y se particiono en ambos el set de validaci√≥n.

- El modulo `src/` es el modulo principal que contiene todas las partes y/o herramientas que conforman este
  mini framework. Este posee una estructura centralizadaa en donde `core/config.py` alamcena
  y carga las los valores de las variables de entorno para que puedan ser asequibles por el resto de modulos,
  y as√≠ no tener que cargar en cada script las variables de entorno que se vayan a utilizar.

- Se evaluo el performance de **MiniNN Framework** con el popular framework de deep learning **Pytorch**
  en una tarea de clasificaci√≥n con el dataset de _fashion-mnist_, en la cual se utilizo exactamente el
  mismo dataset e hiperpatametros para ambas pruebas. Para sacar los resultados del cotejo se guardo en
  formato `json` metricas como el accuracy y la perdida.

  - **[main.py](main.py)**: Este archivo inplmenta el c√≥digo de entrenamiento y la estrcutura de la red que se va a utilizar
    para el cotejo.
  - **[pytorch_comparison](https://colab.research.google.com/drive/1APfspox9ONmDWL0jFXmndHZ70UPjr9Mn?usp=sharing)**: En
    el notebook est√° el c√≥digo de entrenamiento version Pytorch, que realiza el mismo procedimiento que el script.

### Resultados del cotejo:

Ya obtenidos los resultados, se hizo un script ([visualization.py](visualization.py)) para graficar los resultados
de una manera m√°s presentable.

![comparison](images/comparison.png)

## üìÇ Estructura del proyecto

[Structure file](FileTree_NeuralNetwork.md)

```
üìÅ Neural Networks
‚îú‚îÄ‚îÄ üìÅ data
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ FashionMnist
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ Mnist
‚îú‚îÄ‚îÄ üìÅ examples
‚îÇ   ‚îú‚îÄ‚îÄ üêç binary_classification.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç multiclass_classification.py
‚îÇ   ‚îî‚îÄ‚îÄ üêç regresion.py
‚îú‚îÄ‚îÄ üìÅ images
‚îÇ   ‚îî‚îÄ‚îÄ üñºÔ∏è comparison.png
‚îú‚îÄ‚îÄ üìÅ logs
‚îú‚îÄ‚îÄ üìÅ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ exploration.ipynb
‚îú‚îÄ‚îÄ üìÅ src
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ core
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç config.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç dataloader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç init.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç logger.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ layers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ activations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç activations.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç relu.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç sigmoid.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç softmax.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç tanh.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ bn
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç batch_normalization.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ linear
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç linear.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÅ regularization
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç dropout.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ losses
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç functional.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ metrics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ model
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç nn.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç layer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç module.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ optim
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç adam.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç rmsprop.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç sgd.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ üêç utils.py
‚îú‚îÄ‚îÄ üìÅ tests
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ activations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç test_leaky_relu.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç test_relu.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç test_sigmoid.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üêç test_softmax.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç test_tanh.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ batch_norm
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç test_batch_norm.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ dataloader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç test_dataloader.py
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ initializers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üêç test_init.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç test_dropout_regularization.py
‚îÇ   ‚îú‚îÄ‚îÄ üêç test_linear_layer.py
‚îÇ   ‚îî‚îÄ‚îÄ üêç test_sequential_module.py
‚îú‚îÄ‚îÄ ‚öôÔ∏è .gitignore
‚îú‚îÄ‚îÄ üìù FileTree_NeuralNetwork.md
‚îú‚îÄ‚îÄ üìù README.en.md
‚îú‚îÄ‚îÄ üìù README.es.md
‚îú‚îÄ‚îÄ üêç main.py
‚îú‚îÄ‚îÄ üìÑ requirements.txt
‚îî‚îÄ‚îÄ üêç visualization.py
```

## Estructura del modulo `src/` y sub directorios

Aqu√≠ que se va a explicar a detalle que hace cada submodulo y sus archivos

### `core/`

**Centraliza las funciones ecencialies del proyecto**

- `config.py`: Contiene las **configuraciones globales** del proyecto. Ej. Variables de entorno
  y diccionarios con los distintos **metodos de inicializaci√≥n** de parametros para las capas lineales.

  Hay dos diccionarios: `DEFAULT_NORMAL_INIT_MAP` (se usa por defecto en todo el c√≥digo) que contiene las funciones
  de inicializaci√≥n con distribuciones normales (`xavier_normal_`/`kaiming_normal`) del archivo `init.py`  
  y `DEFAULT_UNIFORM_INIT_MAP` contiene las funciones con distribuciones uniformes
  (`xavier_uniform`/`kaiming_uniform`). Como clave de estos diccionarios est√° el nombre de la funci√≥n de
  activaci√≥n que le corresponde a dicha inicialiaci√≥n.

- `dataloder.py`

  - `DataLoader`: Esta clase recibe dos arrays de numpy (x, y) y va a retornar un objeto iterador, el
    iterador va a regresar una tupla con dos arrays (B,features) seg√∫n el tama√±o del `batch_size`, barajandolos
    aleatoriamente si `shuffle` es True.

- `init.py`: Este script que contiene las funciones de inicializaci√≥n de parametros `xavier_normal_`, `xavier_uniform_`,
  `kaiming_normal_`, `kaiming_uniform_` y `random_init_`.

- `logger.py`:
  - `Logger`: Permite la creaci√≥n de un logger de diferentes niveles con una facil configuraci√≥n. Permite agregar
    _kwargs_ para hacer anotaciones adicionales sobre algo en concreto

### `layers/`

- `activations/`

  - `activations.py`

    - `Activation()`: Clase que hereda de `Layer`, esta clase tiene como atributos: `name`, que almacena
      en _lower case_ el nombre de sus sub clases y `affect_init` que ayuda a indicar en si la
      funci√≥n deberia influir en la inicializaci√≥n por defecto, basicamente si esta en False indicaria que su nombre
      no esta en el diccionario de inicializaciones, por lo que se inicializaria con el metodo por defecto `random_init_`

  - `relu.py`

    - `ReLU()`: Clase que hereda de `Activation`, la identifica como un una funci√≥n de activaci√≥n, lo que yuda a
      identificaci√≥n en en modulo `Sequential` para saber que metodo de inicializaci√≥n utilizar averiguando su atributo
      `name` y si tiene o no parametros.
      En su metodo `forward(x)` aplica la funci√≥n relu `(max(0,x))`.
      En su metodo `backward(grad)` retropropaga el gradiente: ‚àÇL/‚àÇa \* œÉ(x)

    - `LeakyReLU()`: Clase que hereda de `Activation`, la identifica como un funci√≥n de activaci√≥n. Esta consta de un
      parametros llamado `negative_slope` que lo que hace es proveer una peque√±a pendiente peque√±a a los valos negtivos
      para evitar las neuronas muertas.
      En su metodo `forward(x)` lo que hace es pasar los valores positivos, y proveer una peque√±a pendiente a los
      negativos `(si x >= 0; x, si no Œ± * x)`.
      En su metodo `backward(grad)` lo que hace es `(si x >= 0, 1.0, si no Œ±)`

  - `sigmoid.py`
    - `Sigmoid()`:...
  - `softmax.py`
    - `Softmax()`:...
  - `tanh.py`
    - `Tanh()`:...

- `bn/`

  - `batch_normalization.py`
    - `BatchNormalization()`:...

- `linear/`

  - `linear.py`
    - `Linear()`:...

- `regularization/`
  - `dropout.py`
    - `Dropout()`:...

### `losses/`

- `functional.py`
  - `CrossEntropyLoss()`:...
  - `MSE()`:...
  - `MAE()`:...
  - `BinaryCrossEntropy()`:...

### `metrics/`

- `metrics.py`
  - `accuracy(...)`:...
  - `binaty_accuracy(...)`:...
  - `r2_score(...)`:...

### `model/`

- `nn.py`
  - `Sequential()`:...

### `module/`

- `layer.py`
  - `Layer()`:...
- `module.py`
  - `Module()`:...

### `optim/`

- `adam.py`
  - `Adam()`:...
- `rmsprop.py`
  - `RMSprop()`:...
- `sgd.py` - `SGD()`:...
  ...

### `utils.py`:...

1. `numeric_grad_elementwise(...)`:...
2. `numeric_grad_scalar_from_softmax(...)`:...
3. `numeric_grad_scalar_wrt_x(...)`:...
4. `numeric_grad_wrt_param(...)`:...
5. `load_fashion_mnist_data(...)`:...
6. `load_mnist_data(...)`:...

## üõ†Ô∏è Tecnolog√≠as utilizadas

- Lenguajes: Python 3.14.0 üêç

- Herramientas de desarrollo: Estenciones: `Black Formatter`, `FileTree Pro`

- Principales Librerias utilizadas:

1.  **`numpy`**: Arrays con opreaciones vectorizadas optimizadas en memoria.
2.  **`pandas`**: Manejo de datos tabulares. Ej. Datasets como _fashion-mnist_ y _mnist_.
3.  **`matplotlib`**: Visualizaci√≥n de datos y graficos estad√≠sticos
4.  **`seaborn`**: Mejorar el estilo de las visualizaciones
5.  **`scikit-learn`**: Libreria de Machine Learning clasico.
6.  **`pyarrow`**: Reducir el gran uso de memor√≠a de pandas con datasets grandes
7.  **`pytest`**: Tests unitarios.

## üì¶ Instalaci√≥n

Instrucciones para instalar dependecias y preparar el entrono

1. **Clonar repositorio**

```bash
git clone https://github.com/JOSE-MDG/mini-nn-framework

# Acceder al directorio
cd "mini-nn-framework"
```

2. **Crear y activar un entorno virtual**

- Windows:

```bash
python -m venv .venv

# Activar entorno virtual
.\\.venv\\Scripts\\activate

# Si el anterior da problemas
.\\.venv\\Scripts\\Activate.Ps1
```

- Linux/MacOS:

```bash
python -m venv .venv

# Activar entorno virtual
source .venv/bin/activate
```

3. **Instalar los requerimientos (`requirements.txt `)**

```bash
pip install -r requirements.txt
```

## üß™ Testing (`tests/`)

...

## ü§ù Contribuci√≥n

...

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo [LICENSE](LICENCE) para m√°s detalles.

## üë§ Author

Juan Jos√© - Developer, Machine & Deep Learning Enthusiast.
GitHub: https://github.com/JOSE-MDG
